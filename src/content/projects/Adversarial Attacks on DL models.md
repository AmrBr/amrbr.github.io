---
title: "Adversarial Attacks on Deeplearning Models"
description: "In this project, we explored the role of Adversarial Machine Learning in Natural Language Processing, focusing on how carefully crafted inputs can expose vulnerabilities in ML models. Our goal was twofold: to evaluate model robustness and to contribute toward building more secure NLP systems.


We implemented and tested both character-level attacks—such as flips, spacing tricks, and inner-letter shuffles—and word-level attacks, including transformer-based strategies like BERT Attack.


What made our work unique was its focus on the Arabic language, which remains underexplored in this domain. Arabic’s complex morphology and script presented unique challenges, making it an ideal testbed for adversarial techniques. Our findings help push forward the understanding of how NLP models can be better secured across diverse languages."

url: "https://github.com/AmrBr/Adversarial-Attacks-on-DL-Models.git"
featured: true
techs:
  - PyTorch
  - Python
  - NLP
  - Research
  - Adversarial ML
---
